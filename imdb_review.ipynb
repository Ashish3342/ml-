{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> IMDB sentiment classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x,label_train),(test_x,label_test)=imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n"
     ]
    }
   ],
   "source": [
    "for sample in range(3):\n",
    "    print(train_x[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for y in range(3):\n",
    "    print(label_train[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the dictionionary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reversing the indexes to their respective words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=imdb.get_word_index()\n",
    "reversed_index=dict([(value,key) for (key,value) in word_index.items()])\n",
    "decoded_review=' '.join([reversed_index.get(i-3,'?') for i in train_x[0]])\n",
    "decoded_review2=' '.join([reversed_index.get(i-3,'?') for i in test_x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? please give this one a miss br br ? ? and the rest of the cast ? terrible performances the show is flat flat flat br br i don't know how michael ? could have allowed this one on his ? he almost seemed to know this wasn't going to work out and his performance was quite ? so all you ? fans give this a miss\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly ? was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little ? that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big ? for the whole film but these children are amazing and should be ? for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was ? with us all\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_f=np.zeros((len(train_x),5000))\n",
    "for i,train_x in enumerate(train_x):\n",
    "    train_f[i,train_x]=1\n",
    "print(train_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "test_f=np.zeros((len(test_x),5000))\n",
    "for i,test_x in enumerate(test_x):\n",
    "    test_f[i,test_x]=1\n",
    "print(test_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorizing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=np.asarray(label_train).astype('float32')\n",
    "label_test=np.asarray(label_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                80016     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(16,activation='relu',input_shape=(5000,)))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 6s 231us/step - loss: 0.3937 - acc: 0.8424\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.2468 - acc: 0.9036\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.2128 - acc: 0.9179\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.1952 - acc: 0.9267\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 0.1816 - acc: 0.9321\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.1709 - acc: 0.9356\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.1583 - acc: 0.9405\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.1477 - acc: 0.9445\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.1365 - acc: 0.9491\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.1240 - acc: 0.9538 0s - loss: 0.1197\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.1134 - acc: 0.9582\n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.1001 - acc: 0.9650\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.0871 - acc: 0.9698\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.0764 - acc: 0.9735\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.0646 - acc: 0.9788\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0544 - acc: 0.9830\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.0452 - acc: 0.9856\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0359 - acc: 0.9894\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 0.0294 - acc: 0.9916\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 0.0228 - acc: 0.9936\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0174 - acc: 0.9958\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 0.0131 - acc: 0.9972\n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0108 - acc: 0.9972\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0074 - acc: 0.9985\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 0.0064 - acc: 0.9983\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 3s 125us/step - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 0.0024 - acc: 0.9994 2s - loss: 0.0013 - acc: 0.99 - \n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 3s 105us/step - loss: 0.0013 - acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "result=model.fit(train_f,label_train,epochs=30,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 115us/step\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(test_f,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 1.346697738431096 and accuracy is : 0.84268\n"
     ]
    }
   ],
   "source": [
    "print('loss is:',loss,'and accuracy is :',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thus we have achieved 84.26% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('imdb_review.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
